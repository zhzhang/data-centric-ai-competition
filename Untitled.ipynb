{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7c42970-8c06-4a74-8189-7ddcdc7b4381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1936 files belonging to 10 classes.\n",
      "Found 827 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Deletes nonsensical examples like smiley faces, hearts, stars, English and Chinese words, unrelated shapes and scribbles.\n",
    "# directory = \"cleaned_nonsensical_examples\"\n",
    "\n",
    "# directory = \"base_data\"\n",
    "directory = \"cleaned_manual_relabeled\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class_names = [\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"]\n",
    "batch_size = 8\n",
    "tf.random.set_seed(123)\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory + '/train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32),\n",
    ")\n",
    "\n",
    "valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory + '/val',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0570be34-750b-4092-8c66-13ff55899d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem_7 ( (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "tf.nn.bias_add_7 (TFOpLambda (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "model_14 (Functional)        (None, 8, 8, 256)         229760    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 232,330\n",
      "Trainable params: 229,386\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 33.3683 - accuracy: 0.0992\n",
      "loss 33.36829376220703, acc 0.09915357083082199\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 2.0010 - accuracy: 0.3120 - val_loss: 1.9306 - val_accuracy: 0.3144\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.4259 - accuracy: 0.5387 - val_loss: 1.6719 - val_accuracy: 0.4160\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.1577 - accuracy: 0.6322 - val_loss: 1.5002 - val_accuracy: 0.4498\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.9419 - accuracy: 0.7097 - val_loss: 1.1834 - val_accuracy: 0.5732\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7914 - accuracy: 0.7531 - val_loss: 1.1448 - val_accuracy: 0.5816\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6991 - accuracy: 0.7789 - val_loss: 1.1364 - val_accuracy: 0.5756\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6065 - accuracy: 0.8182 - val_loss: 0.9618 - val_accuracy: 0.6530\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4989 - accuracy: 0.8523 - val_loss: 1.2154 - val_accuracy: 0.6046\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.8796 - val_loss: 0.9386 - val_accuracy: 0.6578\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3542 - accuracy: 0.9148 - val_loss: 1.2293 - val_accuracy: 0.6022\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3165 - accuracy: 0.9179 - val_loss: 0.9650 - val_accuracy: 0.6505\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2733 - accuracy: 0.9318 - val_loss: 0.8872 - val_accuracy: 0.6759\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2298 - accuracy: 0.9509 - val_loss: 1.0189 - val_accuracy: 0.6445\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2164 - accuracy: 0.9504 - val_loss: 1.4183 - val_accuracy: 0.5659\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.1832 - accuracy: 0.9633 - val_loss: 1.3550 - val_accuracy: 0.5865\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.1421 - accuracy: 0.9747 - val_loss: 1.4781 - val_accuracy: 0.5792\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.1341 - accuracy: 0.9752 - val_loss: 1.2981 - val_accuracy: 0.6421\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.1350 - accuracy: 0.9695 - val_loss: 2.2430 - val_accuracy: 0.5296\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.1340 - accuracy: 0.9716 - val_loss: 1.3058 - val_accuracy: 0.6046\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.1081 - accuracy: 0.9783 - val_loss: 1.4711 - val_accuracy: 0.6094\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.1051 - accuracy: 0.9778 - val_loss: 1.4250 - val_accuracy: 0.5877\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0940 - accuracy: 0.9840 - val_loss: 1.2353 - val_accuracy: 0.6131\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0852 - accuracy: 0.9871 - val_loss: 1.3133 - val_accuracy: 0.6191\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0959 - accuracy: 0.9840 - val_loss: 1.1897 - val_accuracy: 0.6542\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0916 - accuracy: 0.9799 - val_loss: 1.3442 - val_accuracy: 0.6131\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0741 - accuracy: 0.9835 - val_loss: 1.4928 - val_accuracy: 0.5780\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0583 - accuracy: 0.9907 - val_loss: 1.9280 - val_accuracy: 0.5816\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.9876 - val_loss: 1.7494 - val_accuracy: 0.5961\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0654 - accuracy: 0.9871 - val_loss: 2.7403 - val_accuracy: 0.4776\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0669 - accuracy: 0.9850 - val_loss: 1.3420 - val_accuracy: 0.6324\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0605 - accuracy: 0.9866 - val_loss: 1.2092 - val_accuracy: 0.6312\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0589 - accuracy: 0.9876 - val_loss: 1.2001 - val_accuracy: 0.6614\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0514 - accuracy: 0.9892 - val_loss: 1.4438 - val_accuracy: 0.6385\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0705 - accuracy: 0.9824 - val_loss: 1.3946 - val_accuracy: 0.6094\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0657 - accuracy: 0.9819 - val_loss: 1.8339 - val_accuracy: 0.5901\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0456 - accuracy: 0.9902 - val_loss: 1.4529 - val_accuracy: 0.6300\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9871 - val_loss: 1.8696 - val_accuracy: 0.5961\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0529 - accuracy: 0.9902 - val_loss: 1.9140 - val_accuracy: 0.5719\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0687 - accuracy: 0.9830 - val_loss: 1.6550 - val_accuracy: 0.6179\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0418 - accuracy: 0.9923 - val_loss: 1.4780 - val_accuracy: 0.6252\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0391 - accuracy: 0.9897 - val_loss: 2.1147 - val_accuracy: 0.5490\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0349 - accuracy: 0.9917 - val_loss: 1.4559 - val_accuracy: 0.6505\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0517 - accuracy: 0.9876 - val_loss: 1.2376 - val_accuracy: 0.6626\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9954 - val_loss: 1.4447 - val_accuracy: 0.6469\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0225 - accuracy: 0.9974 - val_loss: 1.2990 - val_accuracy: 0.6348\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0321 - accuracy: 0.9943 - val_loss: 1.9671 - val_accuracy: 0.5623\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0546 - accuracy: 0.9871 - val_loss: 1.6690 - val_accuracy: 0.5949\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0457 - accuracy: 0.9892 - val_loss: 1.6466 - val_accuracy: 0.6324\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 2.9067 - val_accuracy: 0.5091\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9902 - val_loss: 1.4503 - val_accuracy: 0.6312\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0186 - accuracy: 0.9985 - val_loss: 1.4325 - val_accuracy: 0.6397\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9979 - val_loss: 1.8394 - val_accuracy: 0.6167\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0498 - accuracy: 0.9866 - val_loss: 2.3436 - val_accuracy: 0.5599\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0302 - accuracy: 0.9954 - val_loss: 1.7343 - val_accuracy: 0.6239\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0236 - accuracy: 0.9964 - val_loss: 1.6367 - val_accuracy: 0.6106\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0372 - accuracy: 0.9928 - val_loss: 1.6624 - val_accuracy: 0.6034\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0457 - accuracy: 0.9876 - val_loss: 1.8568 - val_accuracy: 0.6106\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0268 - accuracy: 0.9943 - val_loss: 1.5625 - val_accuracy: 0.6445\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0221 - accuracy: 0.9964 - val_loss: 1.6351 - val_accuracy: 0.6276\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0207 - accuracy: 0.9964 - val_loss: 1.7164 - val_accuracy: 0.6336\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 1.7337 - val_accuracy: 0.6505\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0364 - accuracy: 0.9912 - val_loss: 1.4887 - val_accuracy: 0.6409\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0234 - accuracy: 0.9954 - val_loss: 1.8117 - val_accuracy: 0.5961\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0222 - accuracy: 0.9954 - val_loss: 1.5723 - val_accuracy: 0.6469\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0431 - accuracy: 0.9886 - val_loss: 1.8465 - val_accuracy: 0.5901\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 1.5325 - val_accuracy: 0.6385\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0233 - accuracy: 0.9959 - val_loss: 1.4313 - val_accuracy: 0.6590\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 1.9061 - val_accuracy: 0.6070\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0268 - accuracy: 0.9948 - val_loss: 1.3908 - val_accuracy: 0.6542\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0271 - accuracy: 0.9948 - val_loss: 1.3142 - val_accuracy: 0.6699\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0440 - accuracy: 0.9876 - val_loss: 1.7303 - val_accuracy: 0.6022\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0289 - accuracy: 0.9928 - val_loss: 1.1698 - val_accuracy: 0.6663\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 1.6322 - val_accuracy: 0.6227\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9990 - val_loss: 1.6645 - val_accuracy: 0.6445\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9995 - val_loss: 1.3288 - val_accuracy: 0.6602\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 1.1674 - val_accuracy: 0.6880\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 1.5381 - val_accuracy: 0.6808\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 1.8700 - val_accuracy: 0.5973\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9938 - val_loss: 1.7127 - val_accuracy: 0.6288\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 1.9406 - val_accuracy: 0.6252\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0316 - accuracy: 0.9907 - val_loss: 1.8032 - val_accuracy: 0.6252\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 1.5049 - val_accuracy: 0.6481\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9959 - val_loss: 1.3108 - val_accuracy: 0.7025\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0295 - accuracy: 0.9917 - val_loss: 1.4826 - val_accuracy: 0.6663\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 1.4427 - val_accuracy: 0.6723\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 1.7956 - val_accuracy: 0.6433\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 1.8941 - val_accuracy: 0.6106\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 1.4905 - val_accuracy: 0.6687\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 1.7363 - val_accuracy: 0.6167\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 1.7426 - val_accuracy: 0.6324\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 1.2089 - val_accuracy: 0.6953\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 3.0204 - val_accuracy: 0.6058\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 1.5507 - val_accuracy: 0.6421\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 1.4931 - val_accuracy: 0.6300\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0172 - accuracy: 0.9959 - val_loss: 1.4075 - val_accuracy: 0.6675\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 1.4673 - val_accuracy: 0.6554\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0315 - accuracy: 0.9928 - val_loss: 1.9826 - val_accuracy: 0.6203\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0412 - accuracy: 0.9886 - val_loss: 1.9354 - val_accuracy: 0.6167\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 1.2596 - val_accuracy: 0.6771\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 1.7767 - val_accuracy: 0.6336\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.3108 - accuracy: 0.7025\n",
      "final loss 1.3107954263687134, final acc 0.702539324760437\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "directory = \"cleaned_nonsensical_examples\"\n",
    "user_data = directory + \"/train\"\n",
    "valid_data = directory + \"/val\"\n",
    "test_data = directory + \"/test\" # this can be the label book, or any other test set you create\n",
    "\n",
    "### DO NOT MODIFY BELOW THIS LINE, THIS IS THE FIXED MODEL ###\n",
    "batch_size = 8\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "total_length = ((train.cardinality() + valid.cardinality()) * batch_size).numpy()\n",
    "if total_length > 10_000:\n",
    "    print(f\"Dataset size larger than 10,000. Got {total_length} examples\")\n",
    "    sys.exit()\n",
    "\n",
    "# test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     test_data,\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"categorical\",\n",
    "#     class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "#     shuffle=False,\n",
    "# )\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    input_shape=(32, 32, 3),\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    ")\n",
    "base_model = tf.keras.Model(\n",
    "    base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\n",
    ")\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "x = base_model(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "model = tf.keras.Model(inputs, x)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "loss_0, acc_0 = model.evaluate(valid)\n",
    "print(f\"loss {loss_0}, acc {acc_0}\")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    epochs=100,\n",
    "    callbacks=[checkpoint],\n",
    ")\n",
    "\n",
    "model.load_weights(\"best_model\")\n",
    "\n",
    "loss, acc = model.evaluate(valid)\n",
    "print(f\"final loss {loss}, final acc {acc}\")\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(test)\n",
    "# print(f\"test loss {test_loss}, test acc {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df3f096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_nonsensical_examples/train/i/abfb5f30-ce5d-11eb-b317-38f9d35ea60f.png 1 3\n",
      "cleaned_nonsensical_examples/train/iv/adeb61fa-ce5d-11eb-b317-38f9d35ea60f.png 4 1\n",
      "cleaned_nonsensical_examples/train/iv/ae0745aa-ce5d-11eb-b317-38f9d35ea60f.png 4 9\n",
      "cleaned_nonsensical_examples/train/iv/ae04c8e8-ce5d-11eb-b317-38f9d35ea60f.png 4 2\n",
      "cleaned_nonsensical_examples/train/iv/adeda65e-ce5d-11eb-b317-38f9d35ea60f.png 4 8\n",
      "cleaned_nonsensical_examples/train/iv/ae3362ac-ce5d-11eb-b317-38f9d35ea60f.png 4 1\n",
      "cleaned_nonsensical_examples/train/iv/ae56204e-ce5d-11eb-b317-38f9d35ea60f.png 4 3\n",
      "cleaned_nonsensical_examples/train/iv/ae698b3e-ce5d-11eb-b317-38f9d35ea60f.png 4 8\n",
      "cleaned_nonsensical_examples/train/iv/ae690c9a-ce5d-11eb-b317-38f9d35ea60f.png 4 1\n",
      "cleaned_nonsensical_examples/train/iv/ae3daffa-ce5d-11eb-b317-38f9d35ea60f.png 4 8\n",
      "cleaned_nonsensical_examples/train/iv/ae13d932-ce5d-11eb-b317-38f9d35ea60f.png 4 8\n",
      "cleaned_nonsensical_examples/train/iv/ae516676-ce5d-11eb-b317-38f9d35ea60f.png 4 8\n",
      "cleaned_nonsensical_examples/train/iv/add92238-ce5d-11eb-b317-38f9d35ea60f.png 4 2\n",
      "cleaned_nonsensical_examples/train/iv/ae6f1bda-ce5d-11eb-b317-38f9d35ea60f.png 4 2\n",
      "cleaned_nonsensical_examples/train/iv/ae587330-ce5d-11eb-b317-38f9d35ea60f.png 4 9\n",
      "cleaned_nonsensical_examples/train/iv/ae7f1d0a-ce5d-11eb-b317-38f9d35ea60f.png 4 3\n",
      "cleaned_nonsensical_examples/train/iv/add76632-ce5d-11eb-b317-38f9d35ea60f.png 4 3\n",
      "cleaned_nonsensical_examples/train/iv/ae2b8a14-ce5d-11eb-b317-38f9d35ea60f.png 4 8\n",
      "cleaned_nonsensical_examples/train/iv/ae63b3c6-ce5d-11eb-b317-38f9d35ea60f.png 4 2\n",
      "cleaned_nonsensical_examples/train/iv/ae7a2b2e-ce5d-11eb-b317-38f9d35ea60f.png 4 9\n",
      "cleaned_nonsensical_examples/train/iv/ae5c7430-ce5d-11eb-b317-38f9d35ea60f.png 4 3\n",
      "cleaned_nonsensical_examples/train/iv/ae19d0bc-ce5d-11eb-b317-38f9d35ea60f.png 4 3\n",
      "cleaned_nonsensical_examples/train/iv/ae09c974-ce5d-11eb-b317-38f9d35ea60f.png 4 1\n",
      "cleaned_nonsensical_examples/train/iv/ae44c560-ce5d-11eb-b317-38f9d35ea60f.png 4 8\n",
      "cleaned_nonsensical_examples/train/vi/aaf6f9aa-ce5d-11eb-b317-38f9d35ea60f.png 6 3\n",
      "cleaned_nonsensical_examples/train/vi/aab97aa8-ce5d-11eb-b317-38f9d35ea60f.png 6 7\n",
      "cleaned_nonsensical_examples/train/vi/aaf5fa78-ce5d-11eb-b317-38f9d35ea60f.png 6 7\n",
      "cleaned_nonsensical_examples/train/vi/ab1785a8-ce5d-11eb-b317-38f9d35ea60f.png 6 10\n",
      "cleaned_nonsensical_examples/train/vi/aac26b40-ce5d-11eb-b317-38f9d35ea60f.png 6 1\n",
      "cleaned_nonsensical_examples/train/v/af6c0ae8-ce5d-11eb-b317-38f9d35ea60f.png 5 4\n",
      "cleaned_nonsensical_examples/train/v/af28ef1a-ce5d-11eb-b317-38f9d35ea60f.png 5 6\n",
      "cleaned_nonsensical_examples/train/v/af23fcb2-ce5d-11eb-b317-38f9d35ea60f.png 5 6\n",
      "cleaned_nonsensical_examples/train/v/af25a03a-ce5d-11eb-b317-38f9d35ea60f.png 5 6\n",
      "cleaned_nonsensical_examples/train/v/af4670e4-ce5d-11eb-b317-38f9d35ea60f.png 5 6\n",
      "cleaned_nonsensical_examples/train/v/af3c6e78-ce5d-11eb-b317-38f9d35ea60f.png 5 10\n",
      "cleaned_nonsensical_examples/train/v/af8dac70-ce5d-11eb-b317-38f9d35ea60f.png 5 6\n",
      "cleaned_nonsensical_examples/train/v/af56a220-ce5d-11eb-b317-38f9d35ea60f.png 5 1\n",
      "cleaned_nonsensical_examples/train/x/af9dd8c0-ce5d-11eb-b317-38f9d35ea60f.png 10 5\n",
      "cleaned_nonsensical_examples/train/x/b00fe12c-ce5d-11eb-b317-38f9d35ea60f.png 10 1\n",
      "cleaned_nonsensical_examples/train/x/af9e6b64-ce5d-11eb-b317-38f9d35ea60f.png 10 5\n",
      "cleaned_nonsensical_examples/train/x/b02931ea-ce5d-11eb-b317-38f9d35ea60f.png 10 1\n",
      "cleaned_nonsensical_examples/train/x/b0062b82-ce5d-11eb-b317-38f9d35ea60f.png 10 1\n",
      "cleaned_nonsensical_examples/train/x/aff41e24-ce5d-11eb-b317-38f9d35ea60f.png 10 5\n",
      "cleaned_nonsensical_examples/train/iii/b03b3520-ce5d-11eb-b317-38f9d35ea60f.png 3 1\n",
      "cleaned_nonsensical_examples/train/vii/acc10410-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/acb887cc-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/aca696f2-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/ac8ab400-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/ac9fc30e-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/accf90de-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/acd602d4-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/acdf311a-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/acb5ff20-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/ac7924b0-ce5d-11eb-b317-38f9d35ea60f.png 7 3\n",
      "cleaned_nonsensical_examples/train/vii/ac905e50-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/acfe951e-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/ac934764-ce5d-11eb-b317-38f9d35ea60f.png 7 3\n",
      "cleaned_nonsensical_examples/train/vii/accb2350-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/acab893c-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/ac7a35c6-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/ac9ac6e2-ce5d-11eb-b317-38f9d35ea60f.png 7 6\n",
      "cleaned_nonsensical_examples/train/vii/acc8e84c-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/vii/ac70cacc-ce5d-11eb-b317-38f9d35ea60f.png 7 8\n",
      "cleaned_nonsensical_examples/train/ix/af0235dc-ce5d-11eb-b317-38f9d35ea60f.png 9 1\n",
      "cleaned_nonsensical_examples/train/ix/aeff0006-ce5d-11eb-b317-38f9d35ea60f.png 9 10\n",
      "cleaned_nonsensical_examples/train/ix/aef17d1e-ce5d-11eb-b317-38f9d35ea60f.png 9 3\n",
      "cleaned_nonsensical_examples/train/ix/aee14818-ce5d-11eb-b317-38f9d35ea60f.png 9 3\n",
      "cleaned_nonsensical_examples/train/ix/aefd90f4-ce5d-11eb-b317-38f9d35ea60f.png 9 1\n",
      "cleaned_nonsensical_examples/train/ix/aecd5c68-ce5d-11eb-b317-38f9d35ea60f.png 9 8\n",
      "cleaned_nonsensical_examples/train/ix/af03e260-ce5d-11eb-b317-38f9d35ea60f.png 9 10\n",
      "cleaned_nonsensical_examples/train/ix/ae96c6da-ce5d-11eb-b317-38f9d35ea60f.png 9 6\n",
      "cleaned_nonsensical_examples/train/ix/aec595aa-ce5d-11eb-b317-38f9d35ea60f.png 9 10\n",
      "cleaned_nonsensical_examples/train/ix/af149164-ce5d-11eb-b317-38f9d35ea60f.png 9 10\n",
      "cleaned_nonsensical_examples/train/ix/aeb1e50a-ce5d-11eb-b317-38f9d35ea60f.png 9 1\n",
      "cleaned_nonsensical_examples/train/ii/ab4e0182-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab450618-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab2ba65a-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab8b2ac6-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab2ddcea-ce5d-11eb-b317-38f9d35ea60f.png 2 6\n",
      "cleaned_nonsensical_examples/train/ii/ab61f57a-ce5d-11eb-b317-38f9d35ea60f.png 2 3\n",
      "cleaned_nonsensical_examples/train/ii/ab7dae96-ce5d-11eb-b317-38f9d35ea60f.png 2 3\n",
      "cleaned_nonsensical_examples/train/ii/ab4aab36-ce5d-11eb-b317-38f9d35ea60f.png 2 3\n",
      "cleaned_nonsensical_examples/train/ii/ab70014c-ce5d-11eb-b317-38f9d35ea60f.png 2 6\n",
      "cleaned_nonsensical_examples/train/ii/ab6581d6-ce5d-11eb-b317-38f9d35ea60f.png 2 3\n",
      "cleaned_nonsensical_examples/train/ii/ab7d33a8-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab48e396-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab73997e-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab419208-ce5d-11eb-b317-38f9d35ea60f.png 2 3\n",
      "cleaned_nonsensical_examples/train/ii/ab3be11e-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab713f76-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n",
      "cleaned_nonsensical_examples/train/ii/ab480bce-ce5d-11eb-b317-38f9d35ea60f.png 2 1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "    return tf.image.resize(img, [32, 32])\n",
    "\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Integer encode the label\n",
    "    return tf.argmax(one_hot)\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return tf.expand_dims(img, axis=0), label\n",
    "\n",
    "\n",
    "for f in glob.glob(directory + '/train/**', recursive=True):\n",
    "    if \".png\" not in f:\n",
    "        continue\n",
    "    img, label = process_path(f)\n",
    "    predicted = tf.math.argmax(model.predict(img), axis=1)\n",
    "    if int(label) != int(predicted):\n",
    "        print(f, int(label) + 1, int(predicted) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db0f3c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2019,), dtype=int64, numpy=array([7, 5, 8, ..., 3, 9, 2])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = model.predict(train_unshuffled)\n",
    "tf.math.argmax(train_predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353b8ed9-a1f8-4f97-8c57-a71812ae6165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 281)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "for f in glob.glob('base_data/train/**', recursive=True):\n",
    "    if \".png\" not in f:\n",
    "        continue\n",
    "    img = mpimg.imread(f)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show(block=True)\n",
    "    print(img.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff7af7",
   "metadata": {},
   "source": [
    "Base Data Validation Accuracy final loss 0.953378438949585, final acc 0.6752767562866211\n",
    "Cleaned nonsensical final loss 0.8655518889427185, final acc 0.7011070251464844\n",
    "\n",
    "Validation data has no mis-scans that are offset by half the image.\n",
    "- Allows extraneous lines on the page.\n",
    "- Allows some hearts and smileys.\n",
    "\n",
    "Flipping, cropping, random erasure are not viable techniques for MNIST because of the geometry of the characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c32fb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
